# docker-compose.yml
version: "3.8"

services:

  ollama:
    image: ollama/ollama
    container_name: ollama
    restart: always
    networks:
      - proxynet
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    # NO entrypoint: ["/entrypoint.sh"] line needed here anymore!
    # NO volumes: - ./entrypoint.sh:/entrypoint.sh line needed anymore!
    command: > # This allows for a multi-line command string
      /bin/sh -c "
      /bin/ollama serve &
      OLLAMA_PID=$!
      echo 'Waiting for Ollama server to start...'
      sleep 10 # Give Ollama a few seconds to fully initialize
      echo 'Downloading Ollama models...'
      ollama pull llama3
      ollama pull llama3-groq-tool-use
      echo 'Model download complete.'
      wait $OLLAMA_PID
      "

  fastapi:
    image: "fastapi:latest"
    build:
        context: ./fastapi
        dockerfile: ./docker/Dockerfile
    restart: always
    container_name: fastapi
    networks:
      - proxynet
    ports:
        - 8000:8000
    expose:
        - 8000

volumes:
  ollama_data:

networks:
  proxynet:
    name: smart_network