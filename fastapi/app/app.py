# app.py

from fastapi import FastAPI, HTTPException, status
from pydantic import BaseModel, Field
from typing import Optional, Any, List, Tuple
import asyncio
import os # Import os for environment variables
from dotenv import load_dotenv, find_dotenv # Import for loading .env

# IMPORTANT CHANGE: Import the correct initialization function from your agent.py file
# Corrected import statement: 'app' is not a package in this Docker context.
from agent import initialize_hierarchical_agent 

load_dotenv(find_dotenv()) # Load environment variables

# Global variables to hold the initialized agent, token, and persona
openapi_agent_instance = None # Renamed for clarity, it's now the main hierarchical agent
global_access_token = None
global_teslabot_persona = "" # New global variable for the persona string

# Pydantic models for API request and response bodies
class AgentQueryRequest(BaseModel):
    message: str = Field(..., example="List all tasks including all attributes.", description="The natural language query to send to the hierarchical agent.")

class IntermediateStep(BaseModel):
    # Updated description to indicate thought process is included
    action: str = Field(..., description="The action taken by the agent (includes its Thought).")
    observation: str = Field(..., description="The observation received after the action.")

class AgentResponse(BaseModel):
    response: str = Field(..., example="Successfully retrieved 5 tasks: Task A, Task B, Task C, Task D, Task E.", description="The final response generated by the hierarchical agent.")
    intermediate_steps: Optional[List[IntermediateStep]] = Field(None, description="The thought process and intermediate steps of the agent.")

class HealthCheckResponse(BaseModel):
    status: str = Field(..., example="ok", description="Status of the API service.")
    agent_initialized: bool = Field(..., example=True, description="Indicates if the hierarchical agent has been successfully initialized.")

class ErrorResponse(BaseModel):
    detail: str = Field(..., example="Agent not initialized. Please try again later.", description="Error message providing details about the issue.")


# FastAPI app instance
app = FastAPI(
    title="Humanoid robot emulation API",
    description="An API to interact with a hierarchical LangChain agent emulating a humanoid robot capable of using the CrowdDrop API and other general tools.",
    version="1.0.0",
)

@app.on_event("startup")
async def startup_event():
    """
    Initializes the hierarchical agent by calling the function from agent.py
    when the FastAPI application starts up.
    """
    global openapi_agent_instance
    global global_access_token
    global global_teslabot_persona # Access the new global variable

    print("FastAPI app starting up: Initializing hierarchical agent...")
    # Unpack all three returned values from initialize_hierarchical_agent
    agent, token, persona = await initialize_hierarchical_agent()
    if agent:
        openapi_agent_instance = agent
        global_access_token = token
        global_teslabot_persona = persona # Store the persona
        print("Hierarchical agent successfully loaded into FastAPI app with persona.")
    else:
        print("Failed to initialize agent during startup.")

@app.post(
    "/chat",
    response_model=AgentResponse,
    status_code=status.HTTP_200_OK,
    summary="Send a chat message to the agent",
    description="""
    Sends a natural language chat message to the underlying LangChain hierarchical agent, which can interact with the CrowdDrop API or answer general questions.

    **Example queries you can try:**
    - "Who or what are you?"
    - "Where are you right now?"
    - "What do you see around you?"
    - "Do you remember what I asked you just now?"
    - "Work on task with id 68852fa8820a34545cb582c4 by using work_on endpoint."
    - "What is the weather like in Potsdam, Germany?"
    """,
    responses={
        status.HTTP_503_SERVICE_UNAVAILABLE: {"model": ErrorResponse, "description": "Agent not initialized"},
        status.HTTP_500_INTERNAL_SERVER_ERROR: {"model": ErrorResponse, "description": "Internal server error during agent processing"},
    },
    tags=["Agent"]
)
async def chat(request_body: AgentQueryRequest) -> AgentResponse:
    """
    Processes a user query using the initialized hierarchical agent.
    Returns intermediate steps, including the agent's thought process.
    """
    global openapi_agent_instance

    if openapi_agent_instance is None:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Agent not initialized. Please try again later. Check server logs for initialization errors."
        )

    if global_access_token is None:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Authentication token not available. Agent cannot make authorized API calls. Check server logs for authentication errors."
        )
    
    user_query = request_body.message
    print(f"Received query: {user_query}")

    # DEBUGGING: Print the chat history before invoking the agent
    # Access the memory via the agent instance
    if openapi_agent_instance.memory:
        print(f"DEBUG: Chat History BEFORE invoke: {openapi_agent_instance.memory.chat_memory.messages}")
    else:
        print("DEBUG: Agent has no memory object attached.")

    try:
        response = await openapi_agent_instance.ainvoke(
            {"input": user_query},
            return_intermediate_steps=True
        )

        # DEBUGGING: Print the chat history AFTER invoking the agent
        if openapi_agent_instance.memory:
            print(f"DEBUG: Chat History AFTER invoke: {openapi_agent_instance.memory.chat_memory.messages}")

        output_content = response.get("output", "No direct output from agent. Check agent's verbose output in server logs for details.")
        
        intermediate_steps_output: List[IntermediateStep] = []
        if 'intermediate_steps' in response and response['intermediate_steps']:
            for step in response['intermediate_steps']:
                agent_action = step[0] # This will be an AgentAction object
                observation = step[1]  # This will be a string observation

                # Extract and format the thought process for AgentType.ZERO_SHOT_REACT_DESCRIPTION
                action_description = ""
                if hasattr(agent_action, 'log') and agent_action.log:
                    # The 'log' contains the full thought, action, and action input as a string
                    action_description += f"{agent_action.log.strip()}" # Capture the raw log
                
                # If the log wasn't complete or for fallback, add tool/input separately
                elif hasattr(agent_action, 'tool'):
                    action_description += f"Action: {agent_action.tool}"
                    if hasattr(agent_action, 'tool_input'):
                        action_description += f"\nAction Input: {agent_action.tool_input}"
                
                # Final fallback
                if not action_description.strip():
                     action_description = str(agent_action)

                intermediate_steps_output.append(
                    IntermediateStep(action=action_description, observation=str(observation))
                )

        return AgentResponse(response=output_content, intermediate_steps=intermediate_steps_output)
    except Exception as e:
        print(f"Error invoking agent: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error processing request with agent: {str(e)}"
        )

@app.get(
    "/health",
    response_model=HealthCheckResponse,
    summary="Health check endpoint",
    description="Checks the health and initialization status of the API server and the hierarchical agent.",
    tags=["Monitoring"]
)
async def health_check() -> HealthCheckResponse:
    """
    Provides a simple health check to indicate if the API is running
    and if the core hierarchical agent has been successfully initialized.
    """
    return HealthCheckResponse(status="ok", agent_initialized=openapi_agent_instance is not None)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8003)
