# Ollama api documentation
https://github.com/ollama/ollama/blob/main/docs/api.md

# run container interactively and donwload llama3 model into container
docker exec -it ollama ollama run llama3